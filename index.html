<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Project Title</title>
  <link rel="stylesheet" href="style.css">
  <style>
    body { font-family: sans-serif; margin: 0 auto; max-width: 900px; padding: 20px; line-height: 1.6; }
    h1, h2, h3 { color: #222; }
    .authors { font-style: italic; font-size: 0.95em; margin-bottom: 10px; }
    .affiliations { font-size: 0.9em; color: #555; margin-bottom: 20px; }
    .section { margin-bottom: 40px; }
    .code-block { background: #f4f4f4; padding: 10px; font-family: monospace; white-space: pre-wrap; }
    table { width: 100%; border-collapse: collapse; margin-top: 10px; }
    th, td { border: 1px solid #ccc; padding: 6px; text-align: center; font-size: 0.85em; }
    footer { font-size: 0.8em; color: #666; margin-top: 50px; border-top: 1px solid #ccc; padding-top: 10px; }
  </style>
</head>
<body>

  <h1>Probabilistic Robustness for Free? Revisiting Its Training with Benchmarking</h1>
  <p class="authors">
    First Author<sup>*</sup>, Second Author<sup>*</sup>, ... Last Author<sup>†</sup><br>
  </p>
  <p class="affiliations">
    1 University A &nbsp;&nbsp; 2 University B &nbsp;&nbsp; 3 Institute C<br>
    * Equal Contribution &nbsp;&nbsp; † Equal Advising
  </p>

  <div class="section">
    <h2>Abstract</h2>
    <p>
      Deep learning models are notoriously vulnerable to imperceptible perturbations. Most existing research centers on adversarial robustness (AR), which evaluates models under worst-case scenarios by examining the existence of deterministic adversarial examples (AEs). In contrast, probabilistic robustness (PR) adopts a statistical perspective, measuring the likelihood of encountering AEs under stochastic perturbations. While PR is widely regarded as a practical complement to AR, training methods specifically designed to improve PR remain underdeveloped compared to adversarial training (AT) for AR. Among the few PR-targeted training methods, we identify some key limitations: i) They use different evaluation metrics, with none of them adopting a comprehensive set;  ii) While AT may also improve PR (as a ''free by-product''), each PR study typically evaluates only a limited subset of AT methods; iii) There is no unified theoretical framework for comparing the generalisability of those training methods. Thus, we introduce PRBench, the first benchmark dedicated to evaluating PR-targeted training methods. PRBench empirically compares most common AT and PR-targeted training methods using a comprehensive set of metrics, including clean accuracy, PR and AR performance, training efficiency, and generalisation error (GE). We also provide theoretical analysis on the GE of PR performance across training methods. Main findings revealed by PRBench include: AT methods are more versatile than PR-targeted training methods in terms of improving both AR and PR performance, while PR-targeted training methods consistently yield lower GE and higher clean accuracy. Finally, we propose KL-PGD, a simple yet effective method that achieves the highest overall ranking in PRBench.
    </p>
  </div>

  <div class="section">
    <h2>Algorithm</h2>
    <p>Our method works as follows:</p>
    <div class="code-block">
For t = 0, 1, ..., T:
  st = [x_adv, y&lt;t]
  Sample top-k tokens V̂ ~ πsafe(·|st)
  For each token z ∈ V̂:
      Qsafe(st, z) = ...
      g(z) = (1/α) · Qsafe + log πsafe(z|st)
  Sample yt ~ softmax over g(z)
  st+1 = [st, yt]
Return y = [y0, y1, ..., yT]
    </div>
  </div>

  <div class="section">
    <h2>Experiment Results</h2>
    <p>We evaluate using attack success rate (ASR) on several models.</p>
    <table>
      <tr>
        <th>Model</th><th>Defense</th><th>ASR (%)</th>
      </tr>
      <tr>
        <td>Model A</td><td>Original</td><td>73.2</td>
      </tr>
      <tr>
        <td>Model A</td><td>Ours</td><td><b>15.3</b></td>
      </tr>
    </table>
  </div>

  <div class="section">
    <h2>BibTeX</h2>
    <div class="code-block">
@misc{your2025paper,
  title={Project Title},
  author={Author Names},
  year={2025},
  url={https://arxiv.org/abs/xxxxx},
}
    </div>
  </div>

  <footer>
    This page is built upon the template from IMMUNELogo (CVPR 2025). Licensed under CC BY-SA 4.0.
  </footer>
</body>
</html>
